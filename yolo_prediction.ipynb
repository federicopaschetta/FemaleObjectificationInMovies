{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # to store data efficiently\n",
    "import numpy as np # to handle numerical operations\n",
    "import random # to generate random numbers\n",
    "import os # to handle operations regarding file system\n",
    "import wget # to download locally images\n",
    "from ultralytics import YOLO # to import YOLO model\n",
    "from tqdm import tqdm # to visualize loop progressions\n",
    "import matplotlib.pyplot as plt # to create visualizations\n",
    "import cv2 # to handle images\n",
    "import re # to identify regu\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting images list with people from COCO dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "anns_df = pd.read_csv('./data/coco_diff/single_anns/person_anns.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58883\n"
     ]
    }
   ],
   "source": [
    "img_url_list = list(anns_df['img_url'].unique())\n",
    "print(len(img_url_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random sampling from that list and download locally images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(24) # to use same collection of images\n",
    "img_sample = random.sample(img_url_list, 2000) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloads images inside list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:00<00:00, 8447.14it/s]\n"
     ]
    }
   ],
   "source": [
    "# Changes cwd (to download image via wget in) and then changes it back\n",
    "old_cwd = os.getcwd()\n",
    "new_cwd = old_cwd+'/imgs'\n",
    "os.chdir(new_cwd)\n",
    "for url in tqdm(img_sample):\n",
    "    try:\n",
    "        file_name = url.split('/')[-1]\n",
    "        file_path = os.path.join(new_cwd, file_name)\n",
    "        \n",
    "        if not os.path.exists(file_path):\n",
    "            wget.download(url)\n",
    "    except Exception as e:\n",
    "        print(f\"\\nError in download of {url}: {e}\")\n",
    "os.chdir(old_cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO(\"./models/YOLO/yolo11n.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_image_cropped(source: str, crop_part: str = None, crop_factor: int = None, fill: bool = False):\n",
    "    for filename in tqdm(os.listdir(source)):\n",
    "        if filename.endswith(('.jpg', 'jpeg', '.png')):\n",
    "            image_path = os.path.join(source, filename)\n",
    "            \n",
    "            image = cv2.imread(image_path)\n",
    "            \n",
    "            if image is None:\n",
    "                print(f\"Error in image loading: {filename}\")\n",
    "                continue\n",
    "            \n",
    "            # Determine if the image is black & white or RGB\n",
    "            if np.all(image[..., 0] == image[..., 1]) and np.all(image[..., 1] == image[..., 2]):\n",
    "                format = 'b&w'\n",
    "            else:\n",
    "                format = 'rgb'\n",
    "            \n",
    "            height, width, _ = image.shape\n",
    "            \n",
    "            if crop_part and crop_factor:\n",
    "                mask = np.zeros_like(image)  # Create a black image of the same shape\n",
    "                if fill == \"red\":\n",
    "                    fill_color = (0, 0, 255)  # BGR format for red\n",
    "                elif fill == \"white\":\n",
    "                    fill_color = (255, 255, 255)  # BGR format for white\n",
    "                elif fill == \"black\" or fill is None:\n",
    "                    fill_color = (0, 0, 0)  # BGR format for black\n",
    "                else:\n",
    "                    print(f\"Invalid fill color: {fill}. Use 'black', 'red', or 'white'.\")\n",
    "                    continue\n",
    "                \n",
    "                if fill:  # Fill the non-cropped regions with the specified color\n",
    "                    if crop_part == \"top\":\n",
    "                        crop_height = height * crop_factor // 100\n",
    "                        mask[:crop_height, :, :] = image[:crop_height, :, :]  # Copy only the top part\n",
    "                        mask[crop_height:, :, :] = fill_color  # Fill the rest\n",
    "                    elif crop_part == \"side\":\n",
    "                        crop_width = width * crop_factor // 100\n",
    "                        mask[:, :crop_width, :] = image[:, :crop_width, :]  # Copy only the left side\n",
    "                        mask[:, crop_width:, :] = fill_color  # Fill the rest\n",
    "                    else:\n",
    "                        print(f\"Invalid crop part for fill: {crop_part}. Use 'top' or 'side'.\")\n",
    "                        continue\n",
    "                    input_image = mask  # Keep only the filled part\n",
    "                else:  # Default cropping behavior\n",
    "                    if crop_part == \"top\":\n",
    "                        input_image = image[:height * crop_factor // 100, :, :]\n",
    "                    elif crop_part == \"side\":\n",
    "                        input_image = image[:, :width * crop_factor // 100, :]\n",
    "                    else:\n",
    "                        print(f\"Invalid crop: {crop_part}. Use 'top' or 'side'.\")\n",
    "                        continue\n",
    "            else: \n",
    "                input_image = image\n",
    "            \n",
    "            # Model prediction\n",
    "            result = model.predict(source=[input_image], verbose=False)\n",
    "            yield [result, image_path, format]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_names = ['All', 'Top25', 'Top50', 'Top75', 'Side25', 'Side50', 'Side75']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get confidence score for both all and cropped images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img_info(res, img_id: str, format: str, detection_list: list) -> None:\n",
    "    # Get mask for class 0\n",
    "        class_mask = res.boxes.cls == 0\n",
    "        \n",
    "        # Get all relevant data in one go\n",
    "        confidences = res.boxes.conf[class_mask]\n",
    "        dimensions = res.boxes.xywhn[class_mask]\n",
    "        \n",
    "        # Print results using zip to iterate both arrays simultaneously\n",
    "        for index, (conf, dim) in enumerate(zip(confidences, dimensions)):\n",
    "            detection_dict = {}  # Crea un nuovo dizionario per ogni rilevamento\n",
    "            detection_dict['Img_ID'] = img_id\n",
    "            detection_dict['Confidence'] = conf.item()\n",
    "            detection_dict['Dimensions'] = dim.tolist()\n",
    "            detection_dict['ID'] = f'{img_id}{index}'\n",
    "            detection_dict['Format'] = format\n",
    "            detection_list.append(detection_dict)\n",
    "        \n",
    "        # Add specific case if no person is detected\n",
    "        if len(confidences) == 0:\n",
    "            detection_dict = {  \n",
    "                'Img_ID': img_id,\n",
    "                'Confidence': 0,\n",
    "                'Dimensions': [],\n",
    "                'ID': img_id,\n",
    "                'Format': format\n",
    "            }\n",
    "            detection_list.append(detection_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confidence_score(result_img, cropped: bool = False) -> list:\n",
    "    detection_list = []\n",
    "    for res in result_img:\n",
    "        format = res[2]  # 'b&w' or 'rgb'\n",
    "        if cropped:\n",
    "            img_id = res[1].split('\\\\')[-1].strip('.jpg').lstrip('0')\n",
    "            res = res[0][0]\n",
    "        else:\n",
    "            img_id = res.path.split('\\\\')[-1].strip('.jpg').lstrip('0')\n",
    "        get_img_info(res, img_id, format, detection_list)\n",
    "    return detection_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_source = './imgs'\n",
    "\n",
    "# predicts_obj_list = []\n",
    "# for name in df_names:\n",
    "#     print(name)\n",
    "#     if bool(re.search(r'\\d', name)):\n",
    "#         direction = (name[:-2]).lower() or None \n",
    "#         crop_factor = int(name[-2:]) or None\n",
    "#         predict_raw = list(predict_image_cropped(img_source, direction, crop_factor))\n",
    "#     else:\n",
    "#         predict_raw = list(predict_image_cropped(img_source))        \n",
    "#     predicts_obj_list.append(confidence_score(predict_raw, cropped=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicts_filled_list = []\n",
    "# for name in df_names:\n",
    "#     if bool(re.search(r'\\d', name)):\n",
    "#         direction = (name[:-2]).lower() or None \n",
    "#         crop_factor = int(name[-2:]) or None\n",
    "#         predict_raw = list(predict_image_cropped(img_source, direction, crop_factor, fill='black'))\n",
    "#         predicts_filled_list.append(confidence_score(predict_raw, cropped=True))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2001 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2001/2001 [04:54<00:00,  6.79it/s]\n",
      "100%|██████████| 2001/2001 [04:18<00:00,  7.74it/s]\n",
      "100%|██████████| 2001/2001 [06:21<00:00,  5.25it/s] \n",
      "100%|██████████| 2001/2001 [09:38<00:00,  3.46it/s]\n",
      "100%|██████████| 2001/2001 [10:44<00:00,  3.10it/s]\n",
      "100%|██████████| 2001/2001 [07:18<00:00,  4.56it/s]\n"
     ]
    }
   ],
   "source": [
    "predicts_filled_red_list = []\n",
    "for name in df_names:\n",
    "    if bool(re.search(r'\\d', name)):\n",
    "        direction = (name[:-2]).lower() or None \n",
    "        crop_factor = int(name[-2:]) or None\n",
    "        predict_raw = list(predict_image_cropped(img_source, direction, crop_factor, fill='red'))\n",
    "        predicts_filled_red_list.append(confidence_score(predict_raw, cropped=True))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2001/2001 [06:06<00:00,  5.46it/s]\n",
      "100%|██████████| 2001/2001 [05:44<00:00,  5.80it/s]\n",
      "100%|██████████| 2001/2001 [05:46<00:00,  5.77it/s]\n",
      "100%|██████████| 2001/2001 [05:30<00:00,  6.06it/s]\n",
      "100%|██████████| 2001/2001 [05:32<00:00,  6.02it/s]\n",
      "100%|██████████| 2001/2001 [05:59<00:00,  5.56it/s]\n"
     ]
    }
   ],
   "source": [
    "predicts_filled_white_list = []\n",
    "for name in df_names:\n",
    "    if bool(re.search(r'\\d', name)):\n",
    "        direction = (name[:-2]).lower() or None \n",
    "        crop_factor = int(name[-2:]) or None\n",
    "        predict_raw = list(predict_image_cropped(img_source, direction, crop_factor, fill='white'))\n",
    "        predicts_filled_white_list.append(confidence_score(predict_raw, cropped=True))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_df_list = []\n",
    "# for obj, name in zip(predicts_obj_list, df_names):\n",
    "#     df = pd.DataFrame(obj).set_index('ID')\n",
    "#     df['x_center'] = df['Dimensions'].apply(lambda x: x[0] if x else np.nan)\n",
    "#     df['y_center'] = df['Dimensions'].apply(lambda x: x[1] if x else np.nan)\n",
    "#     df['width'] = df['Dimensions'].apply(lambda x: x[2] if x else np.nan)\n",
    "#     df['height'] = df['Dimensions'].apply(lambda x: x[3] if x else np.nan)\n",
    "#     df = df.drop(['Dimensions'], axis=1)\n",
    "#     pred_df_list.append(df)\n",
    "#     df.to_csv(f'./data/yolo_prediction/{name}.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_df_list = []\n",
    "# for obj, name in zip(predicts_filled_list, df_names[1:]):\n",
    "#     df = pd.DataFrame(obj).set_index('ID')\n",
    "#     df['x_center'] = df['Dimensions'].apply(lambda x: x[0] if x else np.nan)\n",
    "#     df['y_center'] = df['Dimensions'].apply(lambda x: x[1] if x else np.nan)\n",
    "#     df['width'] = df['Dimensions'].apply(lambda x: x[2] if x else np.nan)\n",
    "#     df['height'] = df['Dimensions'].apply(lambda x: x[3] if x else np.nan)\n",
    "#     df = df.drop(['Dimensions'], axis=1)\n",
    "#     pred_df_list.append(df)\n",
    "#     df.to_csv(f'./data/yolo_prediction/{name}_filled.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df_list = []\n",
    "for obj, name in zip(predicts_filled_red_list, df_names[1:]):\n",
    "    df = pd.DataFrame(obj).set_index('ID')\n",
    "    df['x_center'] = df['Dimensions'].apply(lambda x: x[0] if x else np.nan)\n",
    "    df['y_center'] = df['Dimensions'].apply(lambda x: x[1] if x else np.nan)\n",
    "    df['width'] = df['Dimensions'].apply(lambda x: x[2] if x else np.nan)\n",
    "    df['height'] = df['Dimensions'].apply(lambda x: x[3] if x else np.nan)\n",
    "    df = df.drop(['Dimensions'], axis=1)\n",
    "    pred_df_list.append(df)\n",
    "    df.to_csv(f'./data/yolo_prediction/{name}_red.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df_list = []\n",
    "for obj, name in zip(predicts_filled_white_list, df_names[1:]):\n",
    "    df = pd.DataFrame(obj).set_index('ID')\n",
    "    df['x_center'] = df['Dimensions'].apply(lambda x: x[0] if x else np.nan)\n",
    "    df['y_center'] = df['Dimensions'].apply(lambda x: x[1] if x else np.nan)\n",
    "    df['width'] = df['Dimensions'].apply(lambda x: x[2] if x else np.nan)\n",
    "    df['height'] = df['Dimensions'].apply(lambda x: x[3] if x else np.nan)\n",
    "    df = df.drop(['Dimensions'], axis=1)\n",
    "    pred_df_list.append(df)\n",
    "    df.to_csv(f'./data/yolo_prediction/{name}_white.csv', index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "objWoman",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
