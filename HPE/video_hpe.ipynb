{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rtmlib import Wholebody, draw_skeleton\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'  # cpu, cuda, mps\n",
    "backend = 'onnxruntime'  # opencv, onnxruntime, openvino\n",
    "video_path = '../Movies/output_video.mp4'  # Path al video (o 0 per webcam)\n",
    "output_path = 'output_video.avi'  # Salvataggio del video elaborato\n",
    "openpose_skeleton = True  # True per lo stile OpenPose, False per MMPose\n",
    "keypoints_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load C:\\Users\\fedep\\.cache\\rtmlib\\hub\\checkpoints\\yolox_m_8xb8-300e_humanart-c2c7a14a.onnx with onnxruntime backend\n",
      "load C:\\Users\\fedep\\.cache\\rtmlib\\hub\\checkpoints\\rtmw-x_simcc-cocktail13_pt-ucoco_270e-256x192-fbef0d61_20230925.onnx with onnxruntime backend\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Frames: 100%|██████████| 154/154 [05:33<00:00,  2.17s/frame]\n"
     ]
    }
   ],
   "source": [
    "# Inizializza il modello Wholebody\n",
    "wholebody = Wholebody(to_openpose=openpose_skeleton,\n",
    "                      mode='balanced',  # 'performance', 'lightweight', 'balanced'\n",
    "                      backend=backend, device=device)\n",
    "\n",
    "# Lettura del video\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "if not cap.isOpened():\n",
    "    print(\"Errore nell'aprire il video!\")\n",
    "    exit()\n",
    "\n",
    "total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)) \n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID') \n",
    "out = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "with tqdm(total=total_frames, desc=\"Processing Frames\", unit=\"frame\") as pbar:\n",
    "    keypoints_list = []\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        keypoints, scores = wholebody(frame)\n",
    "        \n",
    "        frame_obj = {\n",
    "            \"frame\": int(cap.get(cv2.CAP_PROP_POS_FRAMES)),\n",
    "        }\n",
    "        \n",
    "        for index, (person_kp, person_score) in enumerate(zip(keypoints, scores)):\n",
    "                person_keypoints = [{\"x\": float(kp[0]), \"y\": float(kp[1]), \"score\": sc} for kp, sc in zip(person_kp, person_score)]\n",
    "                frame_obj[f\"Person{index+1}\"] = person_keypoints\n",
    "        \n",
    "        keypoints_list.append(frame_obj)\n",
    "        img_show = draw_skeleton(frame, keypoints, scores, openpose_skeleton=openpose_skeleton)\n",
    "\n",
    "        out.write(img_show)\n",
    "\n",
    "        pbar.update(1)\n",
    "        \n",
    "with open(\"keypoints.json\", \"w\") as f:\n",
    "    json.dump(keypoints_list, f, indent=4)\n",
    "\n",
    "# Rilascia le risorse\n",
    "cap.release()\n",
    "out.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134\n"
     ]
    }
   ],
   "source": [
    "print(len(keypoints[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "objWoman",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
